import os
import requests
from bs4 import BeautifulSoup
import csv

def get_desktop_path():
    # Obtener la ruta del escritorio según el sistema operativo
    desktop_path = os.path.join(os.path.expanduser('~'), 'Desktop')
    return desktop_path

def scrape_home_depot(search_query):
    # Convertir el espacio en búsqueda en '+', que es el formato de URL de Home Depot
    search_query = search_query.replace(' ', '+')
    # URL de la página de búsqueda de Home Depot
    url = f'https://www.homedepot.com.mx/SearchDisplay?categoryId=&storeId=10351&catalogId=10101&langId=-5&sType=SimpleSearch&resultCatEntryType=2&showResultsPage=true&searchSource=Q&pageView=&beginIndex=0&pageSize=20&searchTerm={search_query}#facet:&productBeginIndex:0&facetLimit:&orderBy:&pageView:grid&minPrice:&maxPrice:&pageSize:&'
    
    # Realizar solicitud HTTP
    response = requests.get(url)
    
    if response.status_code == 200:
        soup = BeautifulSoup(response.content, 'html.parser')
        
        # Encontrar todos los contenedores de productos
        items = soup.find_all('div', class_='product-tile')
        
        desktop_path = get_desktop_path()
        csv_file_path = os.path.join(desktop_path, 'productos_home_depot.csv')
        with open(csv_file_path, 'w', newline='', encoding='utf-8') as csvfile:
            writer = csv.writer(csvfile)
            writer.writerow(['Titulo', 'Precio', 'Enlace'])  # Escribir el encabezado
            
            for item in items:
                try:
                    title = item.find('a', class_='product-description')['title']
                    price = item.find('span', class_='price').text.strip()
                    link = item.find('a', class_='product-image')['href']
                    full_link = f'https://www.homedepot.com.mx{link}'
                    
                    writer.writerow([title, price, full_link])
                except AttributeError:
                    # Si falta algún campo, se omite el producto
                    continue
                
        print(f"Los datos han sido guardados en '{csv_file_path}' en el escritorio.")
    else:
        print("Error al obtener la página:", response.status_code)

# Consulta de búsqueda en Home Depot
search_query = 'gas'

# Llamar a la función de scraping
scrape_home_depot(search_query)